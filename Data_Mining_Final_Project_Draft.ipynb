{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Then we scrap the film review and its label using web scrapping and create csv file from that."
      ],
      "metadata": {
        "id": "aqjd8ypy6Mjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('train.csv')"
      ],
      "metadata": {
        "id": "6cBSIwvVS-lP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "ku6HHO7zS_kw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "d_bvC__vXwep",
        "outputId": "d67d695e-666e-4354-a861-cf30d8dc94a2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      id                                       comment_text  \\\n",
              "0       4a16050093a99092                No, you have to prove that I can't.   \n",
              "1       6bc2122dc27e275a  Re: My major edit summaries \\n\\nI have receive...   \n",
              "2       5570f7207bade92f  I depersonalized it. It's sad how you don't ob...   \n",
              "3       a17d6408ffb98139  Thats because I was blocked before I could dis...   \n",
              "4       11b1d25d77ffd834  I apologise for this, I was just angry with ha...   \n",
              "...                  ...                                                ...   \n",
              "111694  67aada13e8e980a4  Honestly, Olaf, the POV fork argument just doe...   \n",
              "111695  fc671995426240b9  Public Domain Image Needed \\n\\nCan anyone uplo...   \n",
              "111696  b40837a8ba4e5b7e  Unban this ip address or a new online encyclop...   \n",
              "111697  85b7bb9f01b3bef1  RV \\nSorry about the RV, went to check on this...   \n",
              "111698  691694c9d0ac8d3c  Since the name of the mountain was not mention...   \n",
              "\n",
              "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
              "0           0             0        0       0       0              0  \n",
              "1           0             0        0       0       0              0  \n",
              "2           0             0        0       0       0              0  \n",
              "3           0             0        0       0       0              0  \n",
              "4           0             0        0       0       0              0  \n",
              "...       ...           ...      ...     ...     ...            ...  \n",
              "111694      0             0        0       0       0              0  \n",
              "111695      0             0        0       0       0              0  \n",
              "111696      1             0        1       1       1              0  \n",
              "111697      0             0        0       0       0              0  \n",
              "111698      0             0        0       0       0              0  \n",
              "\n",
              "[111699 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0be11989-3c65-4ebf-84fb-2feb3584778a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4a16050093a99092</td>\n",
              "      <td>No, you have to prove that I can't.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6bc2122dc27e275a</td>\n",
              "      <td>Re: My major edit summaries \\n\\nI have receive...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5570f7207bade92f</td>\n",
              "      <td>I depersonalized it. It's sad how you don't ob...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a17d6408ffb98139</td>\n",
              "      <td>Thats because I was blocked before I could dis...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11b1d25d77ffd834</td>\n",
              "      <td>I apologise for this, I was just angry with ha...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111694</th>\n",
              "      <td>67aada13e8e980a4</td>\n",
              "      <td>Honestly, Olaf, the POV fork argument just doe...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111695</th>\n",
              "      <td>fc671995426240b9</td>\n",
              "      <td>Public Domain Image Needed \\n\\nCan anyone uplo...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111696</th>\n",
              "      <td>b40837a8ba4e5b7e</td>\n",
              "      <td>Unban this ip address or a new online encyclop...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111697</th>\n",
              "      <td>85b7bb9f01b3bef1</td>\n",
              "      <td>RV \\nSorry about the RV, went to check on this...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111698</th>\n",
              "      <td>691694c9d0ac8d3c</td>\n",
              "      <td>Since the name of the mountain was not mention...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>111699 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0be11989-3c65-4ebf-84fb-2feb3584778a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0be11989-3c65-4ebf-84fb-2feb3584778a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0be11989-3c65-4ebf-84fb-2feb3584778a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W00r9jPGX4ag",
        "outputId": "a485b7ca-1a7d-4bbd-da43-6b234375bd88"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id               0\n",
              "comment_text     0\n",
              "toxic            0\n",
              "severe_toxic     0\n",
              "obscene          0\n",
              "threat           0\n",
              "insult           0\n",
              "identity_hate    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.iloc[:10000]"
      ],
      "metadata": {
        "id": "sIq5bCoLKK5a"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First, we create RNN (or bag of words approach) to give text and get features from RNN"
      ],
      "metadata": {
        "id": "tb5ecPAF6ENS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class RNN:\n",
        "    def __init__(self, max_words=10000, max_len=150, embed_dim=128, lstm_units=128, dropout=0.2):\n",
        "        self.max_words = max_words\n",
        "        self.max_len = max_len\n",
        "        self.embed_dim = embed_dim\n",
        "        self.lstm_units = lstm_units\n",
        "        self.dropout = dropout\n",
        "        self.tokenizer = Tokenizer(num_words=self.max_words)\n",
        "        self.model = Sequential()\n",
        "        self.model.add(Embedding(input_dim=self.max_words, output_dim=self.embed_dim, input_length=self.max_len))\n",
        "        self.model.add(Bidirectional(LSTM(units=self.lstm_units, dropout=self.dropout, recurrent_dropout=self.dropout)))\n",
        "        self.model.add(Dense(units=1, activation='sigmoid'))\n",
        "        self.model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    def preprocess_data(self, comments, labels):\n",
        "        self.tokenizer.fit_on_texts(comments)\n",
        "        sequences = self.tokenizer.texts_to_sequences(comments)\n",
        "        padded_sequences = pad_sequences(sequences, maxlen=self.max_len)\n",
        "        labels = np.array(labels)\n",
        "        return padded_sequences, labels\n",
        "    \n",
        "    def train_test_split_data(self, X, y, test_size=0.2, random_state=42):\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "        return X_train, X_test, y_train, y_test\n",
        "    \n",
        "    def train_model(self, X_train, y_train, batch_size=32, epochs=1, validation_data=None):\n",
        "        self.model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=validation_data)\n",
        "    \n",
        "    def evaluate_model(self, X_test, y_test):\n",
        "        loss, accuracy = self.model.evaluate(X_test, y_test)\n",
        "        print(\"Test loss:\", loss)\n",
        "        print(\"Test accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "VkPAiiDFJmEd"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comments = df[\"comment_text\"].values.tolist()\n",
        "labels = df[\"toxic\"].values.tolist()\n",
        "\n",
        "rnn = RNN()\n",
        "X, y = rnn.preprocess_data(comments, labels)\n",
        "X_train, X_test, y_train, y_test = rnn.train_test_split_data(X, y)\n",
        "rnn.train_model(X_train, y_train, validation_data=(X_test, y_test))\n",
        "rnn.evaluate_model(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FOKz477JyC2",
        "outputId": "098fecc1-c363-4925-82ad-8047fbdc7660"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "250/250 [==============================] - 187s 728ms/step - loss: 0.2403 - accuracy: 0.9233 - val_loss: 0.1844 - val_accuracy: 0.9430\n",
            "63/63 [==============================] - 6s 90ms/step - loss: 0.1844 - accuracy: 0.9430\n",
            "Test loss: 0.18440699577331543\n",
            "Test accuracy: 0.9430000185966492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Then we get features from each film review. And create huge csv"
      ],
      "metadata": {
        "id": "Ih1G7XWB6VUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "\n",
        "class FeatureExtractor:\n",
        "    def __init__(self, rnn):\n",
        "        self.lstm = rnn.model.layers[1] # this will give lstm layer from rnn\n",
        "        \n",
        "        self.model = Model(inputs=rnn.model.input, outputs=self.lstm.output) # we will create new model that will output the lstm layer directly\n",
        "    \n",
        "    def extract_features(self, X):\n",
        "        return self.model.predict(X)"
      ],
      "metadata": {
        "id": "ytDmdQ6CMBkK"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fe = FeatureExtractor(rnn) # extract features from dataset: 128 features from each row\n",
        "features = fe.extract_features(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7u0hdraWMDHG",
        "outputId": "7feadc26-c39e-4a76-99c1-2e60fd425709"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 31s 98ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRdA-W4KMYcC",
        "outputId": "0ba74c17-bcaa-4fbc-94c1-ee22dea5eabd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 256)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9952u98NYkk",
        "outputId": "dfcfded3-3566-4c71-9fcc-fbcfa423ccc1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.04809287,  0.03946817, -0.06752092, ..., -0.07937111,\n",
              "         0.12188628,  0.17288674],\n",
              "       [ 0.04532965,  0.06307178, -0.04092984, ..., -0.07937111,\n",
              "         0.12188628,  0.17288674],\n",
              "       [-0.00569175, -0.00604582,  0.00714082, ..., -0.07937112,\n",
              "         0.12188628,  0.17288674],\n",
              "       ...,\n",
              "       [ 0.14676838,  0.11157919, -0.18422341, ..., -0.07937111,\n",
              "         0.12188627,  0.17288674],\n",
              "       [ 0.01243918,  0.01899815, -0.03120851, ..., -0.07937111,\n",
              "         0.12188628,  0.17288674],\n",
              "       [ 0.04812531,  0.04296872, -0.04840525, ..., -0.06047022,\n",
              "         0.08444085,  0.16743718]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_dataset = np.concatenate((features, np.array(df.toxic).reshape(-1, 1)), axis=1)\n",
        "new_dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqAezqFlQo54",
        "outputId": "8b33619a-1461-49d7-8ada-d1a9dceff955"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 257)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_dataset = pd.DataFrame(new_dataset)\n",
        "new_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "jGyk6ClxRAhN",
        "outputId": "833468ed-d94d-4685-88c0-a88be69f0618"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0         1         2         3         4         5         6    \\\n",
              "0     0.048093  0.039468 -0.067521 -0.075772  0.057751  0.122186 -0.097414   \n",
              "1     0.045330  0.063072 -0.040930 -0.067218  0.047897  0.071021 -0.123213   \n",
              "2    -0.005692 -0.006046  0.007141 -0.050606  0.059983  0.096358 -0.050049   \n",
              "3     0.105037  0.085000 -0.114389 -0.107287  0.048096  0.077839 -0.177038   \n",
              "4     0.109527  0.085902 -0.134017 -0.114765  0.062802  0.100397 -0.164198   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "9995  0.136193  0.108208 -0.163738 -0.113066  0.056395  0.089491 -0.189886   \n",
              "9996  0.112434  0.090425 -0.122035 -0.113189  0.063966  0.117686 -0.148866   \n",
              "9997  0.146768  0.111579 -0.184223 -0.119454  0.054564  0.098779 -0.196948   \n",
              "9998  0.012439  0.018998 -0.031209 -0.072845  0.078142  0.118645 -0.036426   \n",
              "9999  0.048125  0.042969 -0.048405 -0.091579  0.059990  0.098203 -0.121955   \n",
              "\n",
              "           7         8         9    ...       247       248       249  \\\n",
              "0     0.076574 -0.124151  0.127239  ... -0.443482 -0.300731 -0.345783   \n",
              "1     0.115749 -0.179058  0.154814  ... -0.443482 -0.300731 -0.345783   \n",
              "2     0.040247 -0.073477  0.090478  ... -0.443482 -0.300731 -0.345783   \n",
              "3     0.145880 -0.237300  0.175787  ... -0.443482 -0.300731 -0.345783   \n",
              "4     0.165334 -0.242468  0.189257  ... -0.443482 -0.300731 -0.345783   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "9995  0.201010 -0.267062  0.190707  ... -0.410673 -0.278479 -0.261331   \n",
              "9996  0.133675 -0.223280  0.184527  ... -0.443482 -0.300731 -0.345783   \n",
              "9997  0.214242 -0.273064  0.206679  ... -0.443482 -0.300731 -0.345783   \n",
              "9998  0.054806 -0.089479  0.087507  ... -0.443482 -0.300731 -0.345783   \n",
              "9999  0.078922 -0.185650  0.155844  ... -0.410846 -0.276132 -0.257357   \n",
              "\n",
              "           250       251       252       253       254       255  256  \n",
              "0     0.076296  0.084662  0.039722 -0.079371  0.121886  0.172887  0.0  \n",
              "1     0.076296  0.084662  0.039722 -0.079371  0.121886  0.172887  0.0  \n",
              "2     0.076296  0.084662  0.039722 -0.079371  0.121886  0.172887  0.0  \n",
              "3     0.076296  0.084662  0.039722 -0.079371  0.121886  0.172887  0.0  \n",
              "4     0.076296  0.084662  0.039722 -0.079371  0.121886  0.172887  0.0  \n",
              "...        ...       ...       ...       ...       ...       ...  ...  \n",
              "9995  0.082519  0.097686  0.041910 -0.083716  0.089351  0.169146  0.0  \n",
              "9996  0.076296  0.084662  0.039722 -0.079371  0.121886  0.172887  0.0  \n",
              "9997  0.076296  0.084662  0.039722 -0.079371  0.121886  0.172887  0.0  \n",
              "9998  0.076296  0.084662  0.039722 -0.079371  0.121886  0.172887  0.0  \n",
              "9999  0.073576  0.101146  0.031956 -0.060470  0.084441  0.167437  0.0  \n",
              "\n",
              "[10000 rows x 257 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-862ade3a-b9d2-470d-8912-68afc9f39d68\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>247</th>\n",
              "      <th>248</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "      <th>256</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.048093</td>\n",
              "      <td>0.039468</td>\n",
              "      <td>-0.067521</td>\n",
              "      <td>-0.075772</td>\n",
              "      <td>0.057751</td>\n",
              "      <td>0.122186</td>\n",
              "      <td>-0.097414</td>\n",
              "      <td>0.076574</td>\n",
              "      <td>-0.124151</td>\n",
              "      <td>0.127239</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.443482</td>\n",
              "      <td>-0.300731</td>\n",
              "      <td>-0.345783</td>\n",
              "      <td>0.076296</td>\n",
              "      <td>0.084662</td>\n",
              "      <td>0.039722</td>\n",
              "      <td>-0.079371</td>\n",
              "      <td>0.121886</td>\n",
              "      <td>0.172887</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.045330</td>\n",
              "      <td>0.063072</td>\n",
              "      <td>-0.040930</td>\n",
              "      <td>-0.067218</td>\n",
              "      <td>0.047897</td>\n",
              "      <td>0.071021</td>\n",
              "      <td>-0.123213</td>\n",
              "      <td>0.115749</td>\n",
              "      <td>-0.179058</td>\n",
              "      <td>0.154814</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.443482</td>\n",
              "      <td>-0.300731</td>\n",
              "      <td>-0.345783</td>\n",
              "      <td>0.076296</td>\n",
              "      <td>0.084662</td>\n",
              "      <td>0.039722</td>\n",
              "      <td>-0.079371</td>\n",
              "      <td>0.121886</td>\n",
              "      <td>0.172887</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.005692</td>\n",
              "      <td>-0.006046</td>\n",
              "      <td>0.007141</td>\n",
              "      <td>-0.050606</td>\n",
              "      <td>0.059983</td>\n",
              "      <td>0.096358</td>\n",
              "      <td>-0.050049</td>\n",
              "      <td>0.040247</td>\n",
              "      <td>-0.073477</td>\n",
              "      <td>0.090478</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.443482</td>\n",
              "      <td>-0.300731</td>\n",
              "      <td>-0.345783</td>\n",
              "      <td>0.076296</td>\n",
              "      <td>0.084662</td>\n",
              "      <td>0.039722</td>\n",
              "      <td>-0.079371</td>\n",
              "      <td>0.121886</td>\n",
              "      <td>0.172887</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.105037</td>\n",
              "      <td>0.085000</td>\n",
              "      <td>-0.114389</td>\n",
              "      <td>-0.107287</td>\n",
              "      <td>0.048096</td>\n",
              "      <td>0.077839</td>\n",
              "      <td>-0.177038</td>\n",
              "      <td>0.145880</td>\n",
              "      <td>-0.237300</td>\n",
              "      <td>0.175787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.443482</td>\n",
              "      <td>-0.300731</td>\n",
              "      <td>-0.345783</td>\n",
              "      <td>0.076296</td>\n",
              "      <td>0.084662</td>\n",
              "      <td>0.039722</td>\n",
              "      <td>-0.079371</td>\n",
              "      <td>0.121886</td>\n",
              "      <td>0.172887</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.109527</td>\n",
              "      <td>0.085902</td>\n",
              "      <td>-0.134017</td>\n",
              "      <td>-0.114765</td>\n",
              "      <td>0.062802</td>\n",
              "      <td>0.100397</td>\n",
              "      <td>-0.164198</td>\n",
              "      <td>0.165334</td>\n",
              "      <td>-0.242468</td>\n",
              "      <td>0.189257</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.443482</td>\n",
              "      <td>-0.300731</td>\n",
              "      <td>-0.345783</td>\n",
              "      <td>0.076296</td>\n",
              "      <td>0.084662</td>\n",
              "      <td>0.039722</td>\n",
              "      <td>-0.079371</td>\n",
              "      <td>0.121886</td>\n",
              "      <td>0.172887</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>0.136193</td>\n",
              "      <td>0.108208</td>\n",
              "      <td>-0.163738</td>\n",
              "      <td>-0.113066</td>\n",
              "      <td>0.056395</td>\n",
              "      <td>0.089491</td>\n",
              "      <td>-0.189886</td>\n",
              "      <td>0.201010</td>\n",
              "      <td>-0.267062</td>\n",
              "      <td>0.190707</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.410673</td>\n",
              "      <td>-0.278479</td>\n",
              "      <td>-0.261331</td>\n",
              "      <td>0.082519</td>\n",
              "      <td>0.097686</td>\n",
              "      <td>0.041910</td>\n",
              "      <td>-0.083716</td>\n",
              "      <td>0.089351</td>\n",
              "      <td>0.169146</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>0.112434</td>\n",
              "      <td>0.090425</td>\n",
              "      <td>-0.122035</td>\n",
              "      <td>-0.113189</td>\n",
              "      <td>0.063966</td>\n",
              "      <td>0.117686</td>\n",
              "      <td>-0.148866</td>\n",
              "      <td>0.133675</td>\n",
              "      <td>-0.223280</td>\n",
              "      <td>0.184527</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.443482</td>\n",
              "      <td>-0.300731</td>\n",
              "      <td>-0.345783</td>\n",
              "      <td>0.076296</td>\n",
              "      <td>0.084662</td>\n",
              "      <td>0.039722</td>\n",
              "      <td>-0.079371</td>\n",
              "      <td>0.121886</td>\n",
              "      <td>0.172887</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>0.146768</td>\n",
              "      <td>0.111579</td>\n",
              "      <td>-0.184223</td>\n",
              "      <td>-0.119454</td>\n",
              "      <td>0.054564</td>\n",
              "      <td>0.098779</td>\n",
              "      <td>-0.196948</td>\n",
              "      <td>0.214242</td>\n",
              "      <td>-0.273064</td>\n",
              "      <td>0.206679</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.443482</td>\n",
              "      <td>-0.300731</td>\n",
              "      <td>-0.345783</td>\n",
              "      <td>0.076296</td>\n",
              "      <td>0.084662</td>\n",
              "      <td>0.039722</td>\n",
              "      <td>-0.079371</td>\n",
              "      <td>0.121886</td>\n",
              "      <td>0.172887</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>0.012439</td>\n",
              "      <td>0.018998</td>\n",
              "      <td>-0.031209</td>\n",
              "      <td>-0.072845</td>\n",
              "      <td>0.078142</td>\n",
              "      <td>0.118645</td>\n",
              "      <td>-0.036426</td>\n",
              "      <td>0.054806</td>\n",
              "      <td>-0.089479</td>\n",
              "      <td>0.087507</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.443482</td>\n",
              "      <td>-0.300731</td>\n",
              "      <td>-0.345783</td>\n",
              "      <td>0.076296</td>\n",
              "      <td>0.084662</td>\n",
              "      <td>0.039722</td>\n",
              "      <td>-0.079371</td>\n",
              "      <td>0.121886</td>\n",
              "      <td>0.172887</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>0.048125</td>\n",
              "      <td>0.042969</td>\n",
              "      <td>-0.048405</td>\n",
              "      <td>-0.091579</td>\n",
              "      <td>0.059990</td>\n",
              "      <td>0.098203</td>\n",
              "      <td>-0.121955</td>\n",
              "      <td>0.078922</td>\n",
              "      <td>-0.185650</td>\n",
              "      <td>0.155844</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.410846</td>\n",
              "      <td>-0.276132</td>\n",
              "      <td>-0.257357</td>\n",
              "      <td>0.073576</td>\n",
              "      <td>0.101146</td>\n",
              "      <td>0.031956</td>\n",
              "      <td>-0.060470</td>\n",
              "      <td>0.084441</td>\n",
              "      <td>0.167437</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 257 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-862ade3a-b9d2-470d-8912-68afc9f39d68')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-862ade3a-b9d2-470d-8912-68afc9f39d68 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-862ade3a-b9d2-470d-8912-68afc9f39d68');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_dataset.to_excel('features_from_10k_comment.xlsx', index=False)"
      ],
      "metadata": {
        "id": "a9ffbg6lP6f8"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Then we use LigthGBM or XGBoost to classify reviews for sentiment analysis."
      ],
      "metadata": {
        "id": "Y1D0c_UC6iVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightgbm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yf4VVMVBT9uN",
        "outputId": "51e1ec47-8c8b-4be8-c381-6001b05c0154"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (3.3.5)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from lightgbm) (0.40.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn!=0.22.0 in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.10.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0->lightgbm) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0->lightgbm) (1.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgbm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y = new_dataset[256]\n",
        "X = new_dataset.iloc[::,:256]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = lgbm.LGBMClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "print('Accuracy is ', accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcVbwJ1ISIOi",
        "outputId": "75374edd-ae33-48f9-e8ce-9e49c4dee1f8"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is  0.943\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "model = xgb.XGBClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print('Accuracy is ', accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnSuJlRjW8Za",
        "outputId": "83c45893-8845-48f0-ddab-dcffe3930cfa"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is  0.942\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning with Optuna"
      ],
      "metadata": {
        "id": "ANtOohLtd61s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEugWvO6eAKk",
        "outputId": "2aa2181f-2565-4214-cebd-7a865c210b76"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.1.1-py3-none-any.whl (365 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.65.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0)\n",
            "Collecting alembic>=1.5.0\n",
            "  Downloading alembic-1.10.4-py3-none-any.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.9/212.9 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.10)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.1)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.22.4)\n",
            "Collecting cmaes>=0.9.1\n",
            "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n",
            "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.10.4 cmaes-0.9.1 colorlog-6.7.0 optuna-3.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "\n",
        "import sklearn.datasets\n",
        "import sklearn.ensemble\n",
        "import sklearn.model_selection\n",
        "import sklearn.svm\n",
        "\n",
        "def objective(trial):\n",
        "    x, y = X_train,y_train\n",
        "\n",
        "    classifier_name = trial.suggest_categorical(\"classifier\", [\"Random Forest\",\"XGBoost\", \"LightGBM\",\"GradientBoostingClassifier\" ])\n",
        "    if classifier_name == \"Random Forest\":\n",
        "         from sklearn.ensemble import RandomForestClassifier\n",
        "         max_depth = trial.suggest_int(\"max_depth\", 2,50)\n",
        "         max_features = trial.suggest_int(\"max_features\", 2,50)\n",
        "         classifier_obj = RandomForestClassifier(random_state=17,  max_depth=max_depth, max_features=max_features )\n",
        "        \n",
        "         \n",
        "\n",
        "    elif classifier_name == \"XGBoost\":\n",
        "         from xgboost import XGBClassifier\n",
        "         max_depth = trial.suggest_int(\"max_depth\", 2,50)\n",
        "         max_features = trial.suggest_int(\"max_features\", 2,50)\n",
        "         classifier_obj = XGBClassifier(random_state=17,  max_depth=max_depth, max_features=max_features )\n",
        "        \n",
        "         \n",
        "\n",
        "    elif classifier_name == \"LightGBM\":\n",
        "         import lightgbm as lgb\n",
        "         max_depth = trial.suggest_int(\"max_depth\", 2,50)\n",
        "         max_features = trial.suggest_int(\"max_features\",2,50)\n",
        "         classifier_obj = lgb.LGBMClassifier(random_state=17,  max_depth=max_depth, max_features=max_features )\n",
        "        \n",
        "       \n",
        "       \n",
        "    else:\n",
        "         max_depth = trial.suggest_int(\"max_depth\", 2,50)\n",
        "         max_features = trial.suggest_int(\"max_features\", 2,50)\n",
        "         from sklearn.ensemble import GradientBoostingClassifier\n",
        "         classifier_obj = GradientBoostingClassifier(random_state=17,  max_depth=max_depth, max_features=max_features )\n",
        "        \n",
        "         \n",
        "\n",
        "    accuracy=sklearn.model_selection.cross_val_score(classifier_obj, x, y, n_jobs=-1, cv=3).mean()\n",
        "   \n",
        "    return accuracy\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=20)\n",
        "    print(study.best_trial)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wJOuFUYd97Y",
        "outputId": "ec689296-7aa8-47d2-bcd1-d1573bb6f6c6"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-04-27 21:06:07,424]\u001b[0m A new study created in memory with name: no-name-ff56b661-6b9a-4676-9062-415db6f515ae\u001b[0m\n",
            "\u001b[32m[I 2023-04-27 21:06:19,495]\u001b[0m Trial 0 finished with value: 0.9661250145682277 and parameters: {'classifier': 'GradientBoostingClassifier', 'max_depth': 41, 'max_features': 9}. Best is trial 0 with value: 0.9661250145682277.\u001b[0m\n",
            "\u001b[32m[I 2023-04-27 21:06:25,774]\u001b[0m Trial 1 finished with value: 0.9645000770252555 and parameters: {'classifier': 'Random Forest', 'max_depth': 2, 'max_features': 33}. Best is trial 0 with value: 0.9661250145682277.\u001b[0m\n",
            "\u001b[32m[I 2023-04-27 21:06:45,730]\u001b[0m Trial 2 finished with value: 0.9669999052068979 and parameters: {'classifier': 'Random Forest', 'max_depth': 20, 'max_features': 32}. Best is trial 2 with value: 0.9669999052068979.\u001b[0m\n",
            "\u001b[32m[I 2023-04-27 21:06:58,784]\u001b[0m Trial 3 finished with value: 0.9655002802069097 and parameters: {'classifier': 'LightGBM', 'max_depth': 31, 'max_features': 49}. Best is trial 2 with value: 0.9669999052068979.\u001b[0m\n",
            "\u001b[32m[I 2023-04-27 21:07:34,693]\u001b[0m Trial 4 finished with value: 0.9645001707869788 and parameters: {'classifier': 'XGBoost', 'max_depth': 20, 'max_features': 29}. Best is trial 2 with value: 0.9669999052068979.\u001b[0m\n",
            "\u001b[32m[I 2023-04-27 21:07:44,227]\u001b[0m Trial 5 finished with value: 0.9656253114647241 and parameters: {'classifier': 'LightGBM', 'max_depth': 25, 'max_features': 8}. Best is trial 2 with value: 0.9669999052068979.\u001b[0m\n",
            "\u001b[32m[I 2023-04-27 21:07:55,988]\u001b[0m Trial 6 finished with value: 0.9656250301795547 and parameters: {'classifier': 'Random Forest', 'max_depth': 30, 'max_features': 17}. Best is trial 2 with value: 0.9669999052068979.\u001b[0m\n",
            "\u001b[32m[I 2023-04-27 21:08:04,887]\u001b[0m Trial 7 finished with value: 0.9662502333494886 and parameters: {'classifier': 'LightGBM', 'max_depth': 19, 'max_features': 10}. Best is trial 2 with value: 0.9669999052068979.\u001b[0m\n",
            "\u001b[32m[I 2023-04-27 21:08:22,285]\u001b[0m Trial 8 finished with value: 0.9651250926717432 and parameters: {'classifier': 'Random Forest', 'max_depth': 50, 'max_features': 27}. Best is trial 2 with value: 0.9669999052068979.\u001b[0m\n",
            "\u001b[32m[I 2023-04-27 21:08:40,547]\u001b[0m Trial 9 finished with value: 0.966624858314316 and parameters: {'classifier': 'Random Forest', 'max_depth': 20, 'max_features': 29}. Best is trial 2 with value: 0.9669999052068979.\u001b[0m\n",
            "\u001b[32m[I 2023-04-27 21:09:03,864]\u001b[0m Trial 10 finished with value: 0.9647501395408845 and parameters: {'classifier': 'XGBoost', 'max_depth': 3, 'max_features': 43}. Best is trial 2 with value: 0.9669999052068979.\u001b[0m\n",
            "\u001b[32m[I 2023-04-27 21:09:26,482]\u001b[0m Trial 11 finished with value: 0.966874920829945 and parameters: {'classifier': 'Random Forest', 'max_depth': 13, 'max_features': 37}. Best is trial 2 with value: 0.9669999052068979.\u001b[0m\n",
            "\u001b[32m[I 2023-04-27 21:09:49,585]\u001b[0m Trial 12 finished with value: 0.9662500927069037 and parameters: {'classifier': 'Random Forest', 'max_depth': 10, 'max_features': 38}. Best is trial 2 with value: 0.9669999052068979.\u001b[0m\n",
            "\u001b[32m[I 2023-04-27 21:10:14,997]\u001b[0m Trial 13 finished with value: 0.965749967675646 and parameters: {'classifier': 'GradientBoostingClassifier', 'max_depth': 12, 'max_features': 20}. Best is trial 2 with value: 0.9669999052068979.\u001b[0m\n",
            "\u001b[32m[I 2023-04-27 21:10:40,437]\u001b[0m Trial 14 finished with value: 0.9658749989334604 and parameters: {'classifier': 'Random Forest', 'max_depth': 11, 'max_features': 38}. Best is trial 2 with value: 0.9669999052068979.\u001b[0m\n",
            "\u001b[32m[I 2023-04-27 21:11:12,421]\u001b[0m Trial 15 finished with value: 0.9656251239412778 and parameters: {'classifier': 'Random Forest', 'max_depth': 14, 'max_features': 49}. Best is trial 2 with value: 0.9669999052068979.\u001b[0m\n",
            "\u001b[32m[I 2023-04-27 21:11:25,187]\u001b[0m Trial 16 finished with value: 0.9667498895721306 and parameters: {'classifier': 'Random Forest', 'max_depth': 35, 'max_features': 20}. Best is trial 2 with value: 0.9669999052068979.\u001b[0m\n",
            "\u001b[32m[I 2023-04-27 21:12:01,984]\u001b[0m Trial 17 finished with value: 0.9645001707869788 and parameters: {'classifier': 'XGBoost', 'max_depth': 25, 'max_features': 36}. Best is trial 2 with value: 0.9669999052068979.\u001b[0m\n",
            "\u001b[32m[I 2023-04-27 21:12:31,674]\u001b[0m Trial 18 finished with value: 0.9663751239647183 and parameters: {'classifier': 'GradientBoostingClassifier', 'max_depth': 7, 'max_features': 44}. Best is trial 2 with value: 0.9669999052068979.\u001b[0m\n",
            "\u001b[32m[I 2023-04-27 21:12:58,735]\u001b[0m Trial 19 finished with value: 0.9651250457908814 and parameters: {'classifier': 'Random Forest', 'max_depth': 15, 'max_features': 42}. Best is trial 2 with value: 0.9669999052068979.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FrozenTrial(number=2, state=TrialState.COMPLETE, values=[0.9669999052068979], datetime_start=datetime.datetime(2023, 4, 27, 21, 6, 25, 777374), datetime_complete=datetime.datetime(2023, 4, 27, 21, 6, 45, 729663), params={'classifier': 'Random Forest', 'max_depth': 20, 'max_features': 32}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'classifier': CategoricalDistribution(choices=('Random Forest', 'XGBoost', 'LightGBM', 'GradientBoostingClassifier')), 'max_depth': IntDistribution(high=50, log=False, low=2, step=1), 'max_features': IntDistribution(high=50, log=False, low=2, step=1)}, trial_id=2, value=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "study.best_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOUGgGfYeXkw",
        "outputId": "af5f435f-fa11-43a5-c647-c040a3248c5d"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'classifier': 'Random Forest', 'max_depth': 20, 'max_features': 32}"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "tuned_model = RandomForestClassifier(max_depth = 20, max_features = 32)\n",
        "tuned_model.fit(X_train, y_train)\n",
        "y_pred = tuned_model.predict(X_test)\n",
        "\n",
        "print('Accuracy after tuning is ', accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdx6FinckI0B",
        "outputId": "608a08f2-d8e6-4950-e1b3-a9e74f08e8e5"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy after tuning is  0.944\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparison with State-Of-Art Techniques: Transformers"
      ],
      "metadata": {
        "id": "8d3D7til68-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Svua5O9MXxkT",
        "outputId": "61d999dd-2527-4bf1-ac58-cc122b65a82a"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m107.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install detoxify"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 957
        },
        "id": "EzNjZk8XnF9F",
        "outputId": "2cb33d07-86ac-4b94-f5c2-d2cb090b0739"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting detoxify\n",
            "  Downloading detoxify-0.5.1-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from detoxify) (2.0.0+cu118)\n",
            "Collecting sentencepiece>=0.1.94\n",
            "  Downloading sentencepiece-0.1.98-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.22.1\n",
            "  Downloading transformers-4.22.1-py3-none-any.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.1->detoxify) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.1->detoxify) (2.27.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.1->detoxify) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.1->detoxify) (1.22.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.1->detoxify) (3.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.1->detoxify) (23.1)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.1->detoxify) (4.65.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.1->detoxify) (2022.10.31)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->detoxify) (1.11.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->detoxify) (4.5.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->detoxify) (2.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->detoxify) (3.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->detoxify) (3.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->detoxify) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->detoxify) (16.0.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers==4.22.1->detoxify) (2023.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->detoxify) (2.1.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.22.1->detoxify) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.22.1->detoxify) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.22.1->detoxify) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.22.1->detoxify) (2.0.12)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->detoxify) (1.3.0)\n",
            "Installing collected packages: tokenizers, sentencepiece, transformers, detoxify\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.13.3\n",
            "    Uninstalling tokenizers-0.13.3:\n",
            "      Successfully uninstalled tokenizers-0.13.3\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.28.1\n",
            "    Uninstalling transformers-4.28.1:\n",
            "      Successfully uninstalled transformers-4.28.1\n",
            "Successfully installed detoxify-0.5.1 sentencepiece-0.1.98 tokenizers-0.12.1 transformers-4.22.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tokenizers",
                  "transformers"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from detoxify import Detoxify\n",
        "\n",
        "print(\"Example #1\")\n",
        "print('\\nTRANSFORMERS PERFORMANCE\\n')\n",
        "print('Example sentence:', df['comment_text'].iloc[9000])\n",
        "print(Detoxify('original').predict(df['comment_text'].iloc[9000]))\n",
        "\n",
        "print('\\n\\nOUR PERFORMANCE')\n",
        "print(tuned_model.predict([X.iloc[9000]]))\n",
        "\n",
        "print('\\n\\nActual label')\n",
        "print(df['toxic'].iloc[9000])\n",
        "\n",
        "print(\"\\n\\n\\n\\nExample #2\")\n",
        "print('\\nTRANSFORMERS PERFORMANCE\\n')\n",
        "print('Example sentence:', df['comment_text'].iloc[9001])\n",
        "print(Detoxify('original').predict(df['comment_text'].iloc[9001]))\n",
        "\n",
        "print('\\n\\nOUR PERFORMANCE')\n",
        "print(tuned_model.predict([X.iloc[9001]]))\n",
        "\n",
        "print('\\n\\nActual label')\n",
        "print(df['toxic'].iloc[9001])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7a7ORGRnKX1",
        "outputId": "8cbe2c24-ba0f-4279-a0e3-94bbf9cd6a0a"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example #1\n",
            "\n",
            "TRANSFORMERS PERFORMANCE\n",
            "\n",
            "Example sentence: The PTC is not a critic, but a parents group. They are not reliable for critical reaction. Thank you.\n",
            "{'toxicity': 0.0006550305, 'severe_toxicity': 0.00011618549, 'obscene': 0.00017535572, 'threat': 0.00011278491, 'insult': 0.00017681593, 'identity_attack': 0.00013972318}\n",
            "\n",
            "\n",
            "OUR PERFORMANCE\n",
            "[0.]\n",
            "\n",
            "\n",
            "Actual label\n",
            "0\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Example #2\n",
            "\n",
            "TRANSFORMERS PERFORMANCE\n",
            "\n",
            "Example sentence: \"\n",
            "\n",
            "The titles aren't fictional.  Fiction means \"\"not real.\"\"  Unless Ric wandered around with some kind of holographic projection around his waist, the titles aren't fictional.\"\n",
            "{'toxicity': 0.00075165153, 'severe_toxicity': 0.000110687564, 'obscene': 0.00017966599, 'threat': 0.000109057466, 'insult': 0.00018429189, 'identity_attack': 0.00013785088}\n",
            "\n",
            "\n",
            "OUR PERFORMANCE\n",
            "[0.]\n",
            "\n",
            "\n",
            "Actual label\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DONE!"
      ],
      "metadata": {
        "id": "mYM_CDMioiH9"
      }
    }
  ]
}